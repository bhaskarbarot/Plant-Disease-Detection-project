{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in d:\\bhachu\\.venv\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Defined paths for training and validation datasets (TRAIN_PATH, VALID_PATH) with image size (224, 224) \n",
    "2.load_and_preprocess_data_in_batches() loads images in batches, preprocesses them, and saves as .pkl files.\n",
    "3.Splits the dataset into 80% training and 20% validation using sklearn.model_selection.train_test_split.\n",
    "4.Data Processing: Converts images into CNN-ready tensors and stacks them for efficiency. Handles corrupted images by replacing them with placeholder tensors.\n",
    "5.Data Visualization:\n",
    "Displays one sample image per emotion category.\n",
    "Visualizes batches of images using matplotlib for training verification.\n",
    "7.DataLoader Creation: Implements batch processing for training using DataLoader.\n",
    "8.Error Handling: Manages image loading errors and corrupted files.\n",
    "9.Visualization create png files using matplotlib for visualization \n",
    "Efficient preprocessing optimizes model training and stores processed data to avoid redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images from D:\\bhachu\\plant_project\\Plant_Diseases\\train in batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/38 [00:12<03:54,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data batch to train_cnn_batch_1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 5/38 [00:34<03:40,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data batch to train_cnn_batch_2.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 8/38 [00:52<03:02,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data batch to train_cnn_batch_3.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 10/38 [01:06<02:54,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data batch to train_cnn_batch_4.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 13/38 [01:23<02:24,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data batch to train_cnn_batch_5.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 16/38 [01:38<01:52,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data batch to train_cnn_batch_6.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 18/38 [01:51<01:50,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data batch to train_cnn_batch_7.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 21/38 [02:09<01:35,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data batch to train_cnn_batch_8.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 24/38 [02:27<01:20,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data batch to train_cnn_batch_9.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 26/38 [02:43<01:19,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data batch to train_cnn_batch_10.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 29/38 [03:05<00:59,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data batch to train_cnn_batch_11.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 32/38 [03:22<00:32,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data batch to train_cnn_batch_12.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 35/38 [03:35<00:12,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data batch to train_cnn_batch_13.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 37/38 [03:45<00:04,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data batch to train_cnn_batch_14.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [03:54<00:00,  6.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data batch to train_cnn_batch_15.pkl\n",
      "Saved all batches to disk for train_cnn.\n",
      "Processing images from D:\\bhachu\\plant_project\\Plant_Diseases\\valid in batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 11/38 [00:16<01:24,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data batch to ready_for_plant_valid_cnn_batch_1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 21/38 [00:24<00:14,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data batch to ready_for_plant_valid_cnn_batch_2.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 32/38 [00:40<00:04,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data batch to ready_for_plant_valid_cnn_batch_3.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:53<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data batch to ready_for_plant_valid_cnn_batch_4.pkl\n",
      "Saved all batches to disk for ready_for_plant_valid_cnn.\n",
      "\n",
      "Dataset Processing Completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "TRAIN_PATH = r\"D:\\bhachu\\plant_project\\Plant_Diseases\\train\"\n",
    "VALID_PATH = r\"D:\\bhachu\\plant_project\\Plant_Diseases\\valid\"\n",
    "IMG_SIZE = (224, 224) \n",
    "BATCH_SIZE = 5000 \n",
    "def load_and_preprocess_data_in_batches(data_path, output_file):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = []\n",
    "    classes = sorted(os.listdir(data_path))\n",
    "    class_to_label = {class_name: idx for idx, class_name in enumerate(classes)}\n",
    "    print(f\"Processing images from {data_path} in batches...\")\n",
    "    batch_counter = 0\n",
    "    for class_name in tqdm(classes):\n",
    "        class_names.append(class_name)\n",
    "        class_path = os.path.join(data_path, class_name)\n",
    "        for img_name in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, IMG_SIZE)  \n",
    "            img = img.astype(np.float32) / 255.0  # Normalize to float32\n",
    "            images.append(img)\n",
    "            labels.append(class_to_label[class_name])\n",
    "            if len(images) == BATCH_SIZE:\n",
    "                batch_counter += 1\n",
    "                batch_filename = f\"{output_file}_batch_{batch_counter}.pkl\"\n",
    "                save_processed_data(images, labels, batch_filename)\n",
    "                images.clear()\n",
    "                labels.clear()\n",
    "    if images:\n",
    "        batch_counter += 1\n",
    "        batch_filename = f\"{output_file}_batch_{batch_counter}.pkl\"\n",
    "        save_processed_data(images, labels, batch_filename)\n",
    "\n",
    "    print(f\"Saved all batches to disk for {output_file}.\")\n",
    "    return class_names, class_to_label\n",
    "def save_processed_data(images, labels, filename):\n",
    "    data = {\n",
    "        'images': images,\n",
    "        'labels': labels\n",
    "    }\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Saved processed data batch to {filename}\")\n",
    "def main():\n",
    "    train_class_names, class_to_label = load_and_preprocess_data_in_batches(TRAIN_PATH, 'train_cnn')\n",
    "    valid_class_names, _ = load_and_preprocess_data_in_batches(VALID_PATH, 'ready_for_plant_valid_cnn')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Model Architecture:\n",
    "`Custom CNN with three convolutional blocks.\n",
    "`Filter sizes: 64, 128, and 256.\n",
    "`Fully connected layers: 512 neurons and output layer for multi-class classification (38 classes).\n",
    "2.Activation Functions:\n",
    "`Used ReLU (Rectified Linear Unit) in all layers to introduce non-linearity.\n",
    "3.Pooling and Regularization:\n",
    "`MaxPooling: Applied after each convolutional layer to reduce feature map dimensions.\n",
    "`Batch Normalization: Used for faster convergence and better generalization.\n",
    "`Dropout: Applied (0.5 and 0.3) to prevent overfitting.\n",
    "4.Loss Function:\n",
    "`CrossEntropy Loss for multi-class classification.\n",
    "5.Optimizer:\n",
    "`AdamW with a learning rate of 0.001 and weight decay of 0.01 for adaptive learning and regularization.\n",
    "6.Learning Rate Scheduler:\n",
    "`ReduceLROnPlateau: Dynamically reduced the learning rate when validation loss plateaued.\n",
    "7.Data Augmentation:\n",
    "`Resizing to (224, 224), random horizontal flips, random rotations (10 degrees), and normalization using ImageNet statistics.\n",
    "8.Training Configuration:\n",
    "Epochs: 5 (changed from initial 20 to optimize training time).\n",
    "Batch Size: 64 for both training and validation.\n",
    "Device: Trained using CUDA (GPU) if available.\n",
    "9.Training and Validation Performance:\n",
    "`Separate loops for training and validation.\n",
    "`Computed loss and accuracy in each epoch.\n",
    "10.Accuracy:\n",
    "`Best model weights saved as plant_disease_model_acc_{best_acc}.pth.\n",
    "11.Performance Summary:\n",
    "`The structured approach demonstrated efficient learning, optimized architecture, and best model selection based on validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy', 'Blueberry___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Cherry_(including_sour)___healthy', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_', 'Corn_(maize)___Northern_Leaf_Blight', 'Corn_(maize)___healthy', 'Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy', 'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy', 'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Raspberry___healthy', 'Soybean___healthy', 'Squash___Powdery_mildew', 'Strawberry___Leaf_scorch', 'Strawberry___healthy', 'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Tomato_mosaic_virus', 'Tomato___healthy']\n",
      "Number of classes: 38\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1099/1099 [2:01:09<00:00,  6.61s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4203 Acc: 0.5663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 275/275 [11:42<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6806 Acc: 0.7855\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1099/1099 [1:59:28<00:00,  6.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7793 Acc: 0.7509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 275/275 [11:36<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4491 Acc: 0.8566\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1099/1099 [2:00:27<00:00,  6.58s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5970 Acc: 0.8073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 275/275 [11:41<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3623 Acc: 0.8821\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1099/1099 [2:00:14<00:00,  6.56s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4962 Acc: 0.8395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 275/275 [11:35<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2647 Acc: 0.9146\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1099/1099 [1:58:29<00:00,  6.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4255 Acc: 0.8604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 275/275 [11:38<00:00,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2041 Acc: 0.9352\n",
      "Best Validation Accuracy: 0.9352\n",
      "\n",
      "Best Model Saved: plant_disease_model_acc_0.9352.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#main\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "class AdvancedPlantClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=38):\n",
    "        super(AdvancedPlantClassifier, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "def train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler, num_epochs=5):  #5 epochs\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss, train_corrects = 0.0, 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, desc='Training'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            train_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_acc = train_corrects.double() / len(train_loader.dataset)\n",
    "        print(f'Train Loss: {train_loss:.4f} Acc: {train_acc:.4f}')\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, val_corrects = 0.0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(valid_loader, desc='Validation'):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss = val_loss / len(valid_loader.dataset)\n",
    "        val_acc = val_corrects.double() / len(valid_loader.dataset)\n",
    "        print(f'Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "\n",
    "        # Update best model\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    print(f'Best Validation Accuracy: {best_acc:.4f}')\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_acc\n",
    "\n",
    "def main():\n",
    "    # Data transformations\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'valid': transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    }\n",
    "    train_folder_path = r\"D:\\bhachu\\plant_project\\Plant_Diseases\\train\"\n",
    "    valid_folder_path = r\"D:\\bhachu\\plant_project\\Plant_Diseases\\valid\"\n",
    "    train_dataset = datasets.ImageFolder(train_folder_path, transform=data_transforms['train'])\n",
    "    valid_dataset = datasets.ImageFolder(valid_folder_path, transform=data_transforms['valid'])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0) # data  loaders \n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False, num_workers=0)\n",
    "    print(\"Classes:\", train_dataset.classes)\n",
    "    print(\"Number of classes:\", len(train_dataset.classes))\n",
    "\n",
    "    model = AdvancedPlantClassifier(num_classes=len(train_dataset.classes))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "    trained_model, best_acc = train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler)\n",
    "    model_filename = f'plant_disease_model_acc_{best_acc:.4f}.pth'\n",
    "    torch.save(trained_model.state_dict(), model_filename)\n",
    "    print(f\"\\nBest Model Saved: {model_filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this points i was not break to creating the project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Components:\n",
    "\t1.\tUser Interface Development:\n",
    "\t•\tDesign a Streamlit Application: Create a web interface that allows users to upload images of plant leaves (check for the type of file uploaded).\n",
    "\t•\tInterface Usability: Ensure the application is intuitive and user-friendly, with clear instructions and feedback for users.\n",
    "\t2.\tImage Preprocessing:\n",
    "\t•\tData Preparation: Implement image preprocessing steps such as resizing, normalization, and augmentation to improve model performance.\n",
    "\t•\tDataset Handling: Use the New Plant Diseases Dataset from the Kaggle, which contains images of plant leaves with labeled diseases.\n",
    "\t3.\tDisease Classification:\n",
    "\t•\tCNN Model: Develop and train a Convolutional Neural Network (CNN) model to classify plant diseases based on the uploaded images.\n",
    "\t•\tModel Training: Utilize the dataset from Kaggle for training and testing, applying techniques such as data augmentation and transfer learning to enhance model accuracy.\n",
    "Compare the performance of your model with at least 3 pretrained models. Your model should outperform the existing models\n",
    "\t4.\tPerformance and Optimization:\n",
    "\t•\tModel Evaluation: Assess the CNN model’s performance using metrics like accuracy, precision, and recall.\n",
    "\t•\tSystem Optimization: Ensure the application performs efficiently with minimal latency for real-time predictions.\n",
    "\t5.\tDeployment and Testing:\n",
    "\t•\tApplication Deployment: Deploy the Streamlit application for accessibility by end-users.\n",
    "\t•\tTesting: Conduct extensive testing to ensure the application correctly predicts plant diseases and handles various image inputs effectively.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
